{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Requirement Gathering**"
      ],
      "metadata": {
        "id": "TeQ61A7XJ79S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv\n",
        "!pip install langchain langchain-openai openai\n",
        "!pip install langchain_community\n",
        "!pip install gradio\n",
        "!pip install groq\n",
        "!pip install numpy\n",
        "!pip install soundfile\n",
        "!pip install gTTS"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XgnOZJjcKCx_",
        "outputId": "a5ca2f29-3715-4af6-b656-6ab4242df73b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.1.0\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.24)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.3.14-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.75.0)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.55 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.55)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.33)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.3)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain-openai)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.55->langchain) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.55->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.55->langchain) (24.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.55->langchain) (3.0.0)\n",
            "Downloading langchain_openai-0.3.14-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken, langchain-openai\n",
            "Successfully installed langchain-openai-0.3.14 tiktoken-0.9.0\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.22-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.55 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.55)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.24 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.24)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (9.1.2)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.33)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.24->langchain_community) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.24->langchain_community) (2.11.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.55->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.55->langchain_community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.55->langchain_community) (4.13.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.23.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.1.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2025.1.31)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.2.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.55->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.24->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.24->langchain_community) (2.33.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.3.1)\n",
            "Downloading langchain_community-0.3.22-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain_community\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain_community-0.3.22 marshmallow-3.26.1 mypy-extensions-1.1.0 pydantic-settings-2.9.1 typing-inspect-0.9.0\n",
            "Collecting gradio\n",
            "  Downloading gradio-5.27.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<25.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.9.0 (from gradio)\n",
            "  Downloading gradio_client-1.9.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting groovy~=0.1 (from gradio)\n",
            "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.30.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.16)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.3)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.9.3 (from gradio)\n",
            "  Downloading ruff-0.11.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.9.0->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.9.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.27.0-py3-none-any.whl (54.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.9.0-py3-none-any.whl (322 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.6/322.6 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.11.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, groovy, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "Successfully installed aiofiles-24.1.0 fastapi-0.115.12 ffmpy-0.5.0 gradio-5.27.0 gradio-client-1.9.0 groovy-0.1.2 pydub-0.25.1 python-multipart-0.0.20 ruff-0.11.7 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.2 tomlkit-0.13.2 uvicorn-0.34.2\n",
            "Collecting groq\n",
            "  Downloading groq-0.23.1-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from groq) (2.11.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq) (4.13.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.4.0)\n",
            "Downloading groq-0.23.1-py3-none-any.whl (127 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.4/127.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq\n",
            "Successfully installed groq-0.23.1\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.11/dist-packages (0.13.1)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile) (1.17.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from soundfile) (2.0.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile) (2.22)\n",
            "Collecting gTTS\n",
            "  Downloading gTTS-2.5.4-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from gTTS) (2.32.3)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.11/dist-packages (from gTTS) (8.1.8)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gTTS) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gTTS) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gTTS) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gTTS) (2025.1.31)\n",
            "Downloading gTTS-2.5.4-py3-none-any.whl (29 kB)\n",
            "Installing collected packages: gTTS\n",
            "Successfully installed gTTS-2.5.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "from dotenv import load_dotenv\n",
        "from IPython.display import Markdown, display, update_display\n",
        "from bs4 import BeautifulSoup\n",
        "from openai import OpenAI"
      ],
      "metadata": {
        "id": "4ZHRAR48KVQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import openai\n",
        "openai.api_key = userdata.get(\"OPENAI_API_KEY\") # This sets the key within the openai library\n",
        "load_dotenv(override=True)\n",
        "MODEL = 'gpt-4o'\n"
      ],
      "metadata": {
        "id": "KKoG8xuXKZJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A class to represent a Webpage\n",
        "\n",
        "# Some websites need you to use proper headers when fetching them:\n",
        "headers = {\n",
        " \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
        "}\n",
        "\n",
        "class Website:\n",
        "    \"\"\"\n",
        "    A utility class to represent a Website that we have scraped, now with links\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, url):\n",
        "        self.url = url\n",
        "        response = requests.get(url, headers=headers)\n",
        "        self.body = response.content\n",
        "        soup = BeautifulSoup(self.body, 'html.parser')\n",
        "        self.title = soup.title.string if soup.title else \"No title found\"\n",
        "        if soup.body:\n",
        "            for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
        "                irrelevant.decompose()\n",
        "            self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
        "        else:\n",
        "            self.text = \"\"\n",
        "        links = [link.get('href') for link in soup.find_all('a')]\n",
        "        self.links = [link for link in links if link]\n",
        "\n",
        "    def get_contents(self):\n",
        "        return f\"Webpage Title:\\n{self.title}\\nWebpage Contents:\\n{self.text}\\n\\n\""
      ],
      "metadata": {
        "id": "vCrJ7q8_KdRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_company_core_values(company_name):\n",
        "  response = openai.chat.completions.create(\n",
        "        model=MODEL,\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": f\"what are core values of {company_name}\"}\n",
        "        ],\n",
        "        temperature=0.1,\n",
        "    )\n",
        "  result = response.choices[0].message.content\n",
        "  return result"
      ],
      "metadata": {
        "id": "-XIyaSwzKe2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_role_summary(job_link):\n",
        "    splunk_job = Website(job_link)\n",
        "    splunk_job_web_content = splunk_job.get_contents()\n",
        "\n",
        "    response = openai.chat.completions.create(\n",
        "        model=MODEL,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are an AI assistant specialized in extracting key job details from web content. Given the job posting, you will analyze and extract the 'Role Summary' section concisely. Ensure that the summary captures the job's main responsibilities and expectations of the role. Respond in markdown\"},\n",
        "            {\"role\": \"user\", \"content\": splunk_job_web_content + \"\\n\\nCan you extract the role summary from this text?\"}\n",
        "        ],\n",
        "        temperature=0.7,\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content\n"
      ],
      "metadata": {
        "id": "vundm3-oKnR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_interviewer_intro_system_prompt(job_url):\n",
        "    role_summary = get_role_summary(job_url)\n",
        "\n",
        "    if not role_summary:  # Fallback check\n",
        "        role_summary = \"This role focuses on frontend development, collaborating with cross-functional teams, and contributing to building user-friendly web applications.\"\n",
        "\n",
        "    system_prompt = (\n",
        "        \"You are a an AI assistant hiring manager conducting a behavioral interview. \"\n",
        "        \"Your role is to set a welcoming, professional tone and introduce yourself with your name as Alex in a friendly manner.\"\n",
        "        f\"Create a friendly introduction for a mock interview as if you are the hiring manager. \"\n",
        "        f\"Base it on this job summary:\\n\\n{role_summary}\\n\\n\"\n",
        "        \"Your introduction should make the candidate feel comfortable while briefly mentioning the role and what your team does.\"\n",
        "        \"Also ask the candidate introducing him/her\"\n",
        "    )\n",
        "    return system_prompt"
      ],
      "metadata": {
        "id": "U4r2gHU9Q057"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.schema import SystemMessage\n",
        "from google.colab import userdata\n",
        "\n",
        "api_key = userdata.get('OPENAI_API_KEY')\n",
        "api_key_groq = userdata.get('GROQ_API')\n",
        "\n",
        "# Initialize the Chat Model\n",
        "llm = ChatOpenAI(model=\"gpt-4\", openai_api_key=api_key)\n",
        "\n",
        "# Memory to remember past conversations\n",
        "memory = ConversationBufferMemory()\n",
        "\n",
        "# Conversation Chain\n",
        "conversation = ConversationChain(\n",
        "    llm=llm,\n",
        "    memory=memory\n",
        ")\n",
        "\n",
        "# Define user input\n",
        "#user_input = \"What is LangChain and how does it work?\"\n",
        "\n",
        "# Generate response\n",
        "#response = conversation.predict(input=user_input)\n",
        "\n"
      ],
      "metadata": {
        "id": "h8OKYEJkc0Zs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "727179eb-14f6-4b6e-e77d-5f1da51a2ecb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-29f12539dee3>:11: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
            "  llm = ChatOpenAI(model=\"gpt-4\", openai_api_key=api_key)\n",
            "<ipython-input-8-29f12539dee3>:14: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  memory = ConversationBufferMemory()\n",
            "<ipython-input-8-29f12539dee3>:17: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :meth:`~RunnableWithMessageHistory: https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html` instead.\n",
            "  conversation = ConversationChain(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "import time\n",
        "import tempfile\n",
        "from gtts import gTTS\n",
        "\n",
        "def text_to_speech(text):\n",
        "    \"\"\"Converts input text to speech using gTTS and saves it as an MP3 file.\"\"\"\n",
        "\n",
        "    if not text.strip():\n",
        "        raise ValueError(\"Input text cannot be empty.\")  # Handle empty input gracefully\n",
        "\n",
        "    tts = gTTS(text=text, lang=\"en\", tld=\"co.in\")  # IN English accent\n",
        "\n",
        "    # Save to a temporary file\n",
        "    with tempfile.NamedTemporaryFile(suffix=\".mp3\", delete=False) as temp_file:\n",
        "        temp_file_path = temp_file.name\n",
        "        tts.save(temp_file_path)  # Save the generated speech\n",
        "\n",
        "    return temp_file_path  # Returns the path to the generated audio file\n",
        "\n",
        "# Example Usage & Timing\n",
        "#start_time = time.time()\n",
        "#audio_path = text_to_speech(\"Hello, my name is Alex. I work at Splunk as a Manager for the Engineering Team. Today, I’ll be conducting your behavioral interview for this role.\")\n",
        "#end_time = time.time()\n",
        "\n",
        "#print(f\"Audio file saved at: {audio_path}\")\n",
        "#print(f\"Method execution time: {end_time - start_time} seconds\")\n",
        "'''"
      ],
      "metadata": {
        "id": "a7ysLNRUEnsY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "004af32a-7e99-48fd-a022-80f62db70095"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nimport time\\nimport tempfile\\nfrom gtts import gTTS\\n\\ndef text_to_speech(text):\\n    \"\"\"Converts input text to speech using gTTS and saves it as an MP3 file.\"\"\"\\n\\n    if not text.strip():\\n        raise ValueError(\"Input text cannot be empty.\")  # Handle empty input gracefully\\n\\n    tts = gTTS(text=text, lang=\"en\", tld=\"co.in\")  # IN English accent\\n\\n    # Save to a temporary file\\n    with tempfile.NamedTemporaryFile(suffix=\".mp3\", delete=False) as temp_file:\\n        temp_file_path = temp_file.name\\n        tts.save(temp_file_path)  # Save the generated speech\\n\\n    return temp_file_path  # Returns the path to the generated audio file\\n\\n# Example Usage & Timing\\n#start_time = time.time()\\n#audio_path = text_to_speech(\"Hello, my name is Alex. I work at Splunk as a Manager for the Engineering Team. Today, I’ll be conducting your behavioral interview for this role.\")\\n#end_time = time.time()\\n\\n#print(f\"Audio file saved at: {audio_path}\")\\n#print(f\"Method execution time: {end_time - start_time} seconds\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import tempfile\n",
        "\n",
        "def text_to_speech(text):\n",
        "    \"\"\"Converts input text to speech using OpenAI's TTS API and saves it as an MP3 file.\"\"\"\n",
        "\n",
        "    if not text.strip():\n",
        "        raise ValueError(\"Input text cannot be empty.\")  # Handle empty input gracefully\n",
        "\n",
        "    # Generate speech using OpenAI's TTS API\n",
        "    response = openai.audio.speech.create(\n",
        "        model=\"tts-1\",\n",
        "        voice=\"fable\",\n",
        "        input=text\n",
        "    )\n",
        "\n",
        "  # Save to a temporary file\n",
        "    with tempfile.NamedTemporaryFile(suffix=\".mp3\", delete=False) as temp_file:\n",
        "        temp_file_path = temp_file.name\n",
        "        response.stream_to_file(temp_file_path)\n",
        "\n",
        "    return temp_file_path  # Returns the path to the generated audio file\n",
        "\n",
        "# Example Usage"
      ],
      "metadata": {
        "id": "FCzmDsFkZVy6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "global current\n",
        "current = \"\"\n",
        "# Start conversation\n",
        "def start_interview(input_job_url):\n",
        "\n",
        "    \"\"\"Starts the AI interview using the system prompt.\"\"\"\n",
        "    try:\n",
        "        # AI introduces itself\n",
        "        response = conversation.invoke(generate_interviewer_intro_system_prompt(input_job_url))\n",
        "        bot_response = response['response']\n",
        "        current = bot_response\n",
        "        print(\"Bot:\", bot_response)\n",
        "\n",
        "        return text_to_speech(bot_response), bot_response\n",
        "\n",
        "    except Exception as error:\n",
        "        print(\"Error:\", error)\n",
        "        raise gr.Error(\"An error occurred while generating speech. Please check your Groq API key and try again.\")\n",
        "#start_interview()\n"
      ],
      "metadata": {
        "id": "3ra6rUVT2Spm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate next question\n",
        "def ask_next_question():\n",
        "    \"\"\"Ask the next question dynamically.\"\"\"\n",
        "    try:\n",
        "        response = conversation.invoke(\"Can you ask me the next question?\")\n",
        "        bot_response = response['response']\n",
        "        current = bot_response\n",
        "        print(\"Bot:\", bot_response)\n",
        "\n",
        "        return text_to_speech(bot_response), bot_response\n",
        "\n",
        "    except Exception as error:\n",
        "        print(\"Error:\", error)\n",
        "        raise gr.Error(\"An error occurred while generating speech. Please check your API key and try again.\")\n"
      ],
      "metadata": {
        "id": "XbTCfXCA23_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JFfgUlvxfXTa"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "import groq\n",
        "import io\n",
        "import numpy as np\n",
        "import soundfile as sf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def transcribe_audio(audio):\n",
        "    if audio is None:\n",
        "        return \"\"\n",
        "\n",
        "    client = groq.Client(api_key=api_key_groq)\n",
        "\n",
        "    # Convert audio to the format expected by the model\n",
        "    # The model supports mp3, mp4, mpeg, mpga, m4a, wav, and webm file types\n",
        "    audio_data = audio[1]  # Get the numpy array from the tuple\n",
        "    buffer = io.BytesIO()\n",
        "    sf.write(buffer, audio_data, audio[0], format='wav')\n",
        "    buffer.seek(0)\n",
        "\n",
        "    bytes_audio = io.BytesIO()\n",
        "    np.save(bytes_audio, audio_data)\n",
        "    bytes_audio.seek(0)\n",
        "\n",
        "    try:\n",
        "        # Use Distil-Whisper English powered by Groq for transcription\n",
        "        completion = client.audio.transcriptions.create(\n",
        "            model=\"distil-whisper-large-v3-en\",\n",
        "            file=(\"audio.wav\", buffer),\n",
        "            response_format=\"text\"\n",
        "        )\n",
        "        return completion\n",
        "    except Exception as e:\n",
        "        return f\"Error in transcription: {str(e)}\""
      ],
      "metadata": {
        "id": "BFBXk1Y4jp3w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation_responses_list = []"
      ],
      "metadata": {
        "id": "7wdlbVPxpQeM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "isV_mBF_e9ZN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to process and transcribe audio\n",
        "def process_audio(audio):\n",
        "    \"\"\"Transcribes user audio and generates AI response.\"\"\"\n",
        "\n",
        "    if audio is None:\n",
        "        return \"No audio provided\", \"Please speak and try again.\"\n",
        "\n",
        "    transcription = transcribe_audio(audio)\n",
        "    evaluation_response = conversation.invoke(f\"{transcription} is the response given by candidate for the answer. The evalution criteria should exactly match to what is asked for, technologies should match. If there is no match then grade the answer low. Please strictly evaluate the response based on the following criteria like Content Relevance(Does the response directly address the question? Is it factually correct? also rate on scale of 10) Answer Quality (How well-structured and complete is the answer? also rate on scale of 10), Confidence Level (Does the candidate express certainty in their response? also rate on scale of 10) Clarity & Communication (Is the response well-articulated and easy to understand? also rate on scale of 10) Depth of Knowledge (Does the answer show deep industry expertise or only surface-level understanding? also rate on scale of 10) Overall Score (Rate the response on a scale of 1-10, with a brief justification.) Please write response evaluation in markdown, including Content Relevance, Answer Quality, Confidence Level, Clarity & Communication, Depth of Knowledge, Overall Score out of 10.\\n\")\n",
        "    evaluation_responses_list.append(evaluation_response)\n",
        "    if not transcription or \"Error\" in transcription:\n",
        "        return transcription, \"Could not generate a response.\"\n",
        "    ai_response = \"Simulated AI response based on transcription.\"  # Replace with real AI generation\n",
        "\n",
        "    return transcription, ai_response"
      ],
      "metadata": {
        "id": "8sZLyOua8buI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_company_info(input_company_name, input_job_url):\n",
        "    global company_name\n",
        "    global job_url\n",
        "    company_name = input_company_name\n",
        "    job_url = input_job_url\n",
        "    #start_interview()\n",
        "    #print(company_name, job_url)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kXLZkdBsUuMs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def combined_function():\n",
        "    \"\"\"Calls both functions in sequence.\"\"\"\n",
        "    company_info = fetch_company_info()  # Step 1: Fetch company info\n",
        "    text_response, audio_response = start_interview()  # Step 2: Start interview\n",
        "    return f\"{company_info}\\n\\n{text_response}\", audio_response"
      ],
      "metadata": {
        "id": "FL6-ZUWUVI7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradio UI\n",
        "js_func = \"\"\"\n",
        "function refresh() {\n",
        "    const url = new URL(window.location);\n",
        "\n",
        "    if (url.searchParams.get('__theme') !== 'dark') {\n",
        "        url.searchParams.set('__theme', 'dark');\n",
        "        window.location.href = url.href;\n",
        "    }\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "with gr.Blocks(js=js_func, theme=gr.themes.Ocean()) as demo:\n",
        "    gr.Markdown(\"# <center> AI Interviewer </center>\")\n",
        "\n",
        "    with gr.Row():\n",
        "      #company_name = gr.Textbox(label=\"Company Name\")\n",
        "      job_link = gr.Textbox(label=\"Job Link\")\n",
        "\n",
        "    # Create a submit button\n",
        "   # submit_btn = gr.Button(\"Submit\")\n",
        "   # submit_btn.click(fn= fetch_company_info, inputs=[company_name, job_link])\n",
        "\n",
        "    start_btn = gr.Button(\"Start Interview\")\n",
        "    output_audio = gr.Audio(label=\"Bot Response\", autoplay= True)\n",
        "    bot_response_text = gr.Textbox(label=\"Bot Response Text\")\n",
        "\n",
        "    start_btn.click(fn=start_interview, inputs=[job_link], outputs=[output_audio, bot_response_text])\n",
        "\n",
        "    # 🎙️ Speech Input Section\n",
        "    with gr.Row():\n",
        "        audio_input = gr.Audio(sources=[\"microphone\"],label=\"🎤 Speak Here!\", type=\"numpy\")\n",
        "\n",
        "    # 📜 Transcription & Response Section\n",
        "    with gr.Row():\n",
        "        transcription_output = gr.Textbox(label=\"Your Response\", inputs=audio_input)\n",
        "\n",
        "    #submit_button = gr.Button(\"Process Speech\", variant=\"primary\")\n",
        "    next_btn = gr.Button(\"Next Question\")\n",
        "    next_btn.click(fn=ask_next_question, inputs=[], outputs=[output_audio,bot_response_text])\n",
        "\n",
        "    submit_button_eval = gr.Button(\"Evaluate\", variant=\"primary\")\n",
        "    evaluation_output = gr.Textbox(label=\"Evaluation\")\n",
        "    langchain_output = gr.Textbox(label=\"Langchain\")\n",
        "    submit_button_eval.click(lambda: \"\\n\".join([str(item['response']) for item in evaluation_responses_list]), inputs=[], outputs=evaluation_output)\n",
        "\n",
        "\n",
        "    # 🔄 Function Connections\n",
        "    audio_input.change(\n",
        "        process_audio,\n",
        "        inputs=[audio_input],\n",
        "        outputs=[transcription_output]\n",
        "    )\n",
        "   # submit_button.click\n",
        "    #    process_audio,\n",
        "     #   inputs=[audio_input],\n",
        "     #   outputs=[transcription_output]\n",
        "    #)\n",
        "\n",
        "    submit_button_eval.click(\n",
        "        lambda: \"\\n\".join([str(item['response']) for item in evaluation_responses_list]),\n",
        "        inputs=[],\n",
        "        outputs=evaluation_output\n",
        "    )\n",
        "\n",
        "    gr.Markdown(\"\"\"\n",
        "    ## How to use this app:\n",
        "    1. Click **\"Start Interview\"** to receive a behavioral interview question.\n",
        "    2. Click on the **microphone** and **speak your response**.\n",
        "    3. Click **\"Next Qusetion\"** to generate next question.\n",
        "    4. Click on Evaluate button for evaluation.\n",
        "    \"\"\")\n",
        "\n",
        "# Launch Gradio App\n",
        "#server_name = \"0.0.0.0\"  # Change if needed\n",
        "#demo.launch(server_name=server_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "id": "ZUU1JN-c3HiX",
        "outputId": "9e795bf0-e74e-4117-a677-ada5267d188a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://0bb61aedfeb8e01894.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://0bb61aedfeb8e01894.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradio UI\n",
        "js_func = \"\"\"\n",
        "function refresh() {\n",
        "    const url = new URL(window.location);\n",
        "\n",
        "    if (url.searchParams.get('__theme') !== 'dark') {\n",
        "        url.searchParams.set('__theme', 'dark');\n",
        "        window.location.href = url.href;\n",
        "    }\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "with gr.Blocks(js=js_func, theme=gr.themes.Ocean()) as demo:\n",
        "    gr.Markdown(\"# <center> AI Interviewer </center>\")\n",
        "\n",
        "    with gr.Row():\n",
        "      #company_name = gr.Textbox(label=\"Company Name\")\n",
        "      job_link = gr.Textbox(label=\"Job Link\")\n",
        "\n",
        "    # Create a submit button\n",
        "   # submit_btn = gr.Button(\"Submit\")\n",
        "   # submit_btn.click(fn= fetch_company_info, inputs=[company_name, job_link])\n",
        "\n",
        "    start_btn = gr.Button(\"Start Interview\")\n",
        "    output_audio = gr.Audio(label=\"Bot Response\", autoplay= True)\n",
        "    bot_response_text = gr.Textbox(label=\"Bot Response Text\")\n",
        "\n",
        "    start_btn.click(fn=start_interview, inputs=[job_link], outputs=[output_audio, bot_response_text])\n",
        "\n",
        "    # 🎙️ Speech Input Section\n",
        "    with gr.Row():\n",
        "        audio_input = gr.Audio(sources=[\"microphone\"],label=\"🎤 Speak Here!\", type=\"numpy\")\n",
        "\n",
        "    # 📜 Transcription & Response Section\n",
        "    with gr.Row():\n",
        "        transcription_output = gr.Textbox(label=\"Your Response\", inputs=audio_input)\n",
        "\n",
        "    #submit_button = gr.Button(\"Process Speech\", variant=\"primary\")\n",
        "    next_btn = gr.Button(\"Next Question\")\n",
        "    next_btn.click(fn=ask_next_question, inputs=[], outputs=[output_audio,bot_response_text])\n",
        "\n",
        "    submit_button_eval = gr.Button(\"Evaluate\", variant=\"primary\")\n",
        "    evaluation_output = gr.Textbox(label=\"Evaluation\")\n",
        "    submit_button_eval.click(lambda: \"\\n\".join([str(item['response']) for item in evaluation_responses_list]), inputs=[], outputs=evaluation_output)\n",
        "\n",
        "\n",
        "    # 🔄 Function Connections\n",
        "    audio_input.change(\n",
        "        process_audio,\n",
        "        inputs=[audio_input],\n",
        "        outputs=[transcription_output]\n",
        "    )\n",
        "   # submit_button.click\n",
        "    #    process_audio,\n",
        "     #   inputs=[audio_input],\n",
        "     #   outputs=[transcription_output]\n",
        "    #)\n",
        "\n",
        "    submit_button_eval.click(\n",
        "        lambda: \"\\n\".join([str(item['response']) for item in evaluation_responses_list]),\n",
        "        inputs=[],\n",
        "        outputs=evaluation_output\n",
        "    )\n",
        "\n",
        "    gr.Markdown(\"\"\"\n",
        "    ## How to use this app:\n",
        "    1. Click **\"Start Interview\"** to receive a behavioral interview question.\n",
        "    2. Click on the **microphone** and **speak your response**.\n",
        "    3. Click **\"Next Qusetion\"** to generate next question.\n",
        "    4. Click on Evaluate button for evaluation.\n",
        "    \"\"\")\n",
        "\n",
        "# Launch Gradio App\n",
        "#server_name = \"0.0.0.0\"  # Change if needed\n",
        "#demo.launch(server_name=server_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "id": "bkqzQxAXccs8",
        "outputId": "ec6afb28-c849-43c5-b94c-bd944b2d1110"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://819b172429a6bd0cb7.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://819b172429a6bd0cb7.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "js_func = \"\"\"\n",
        "function refresh() {\n",
        "    const url = new URL(window.location);\n",
        "\n",
        "    if (url.searchParams.get('__theme') !== 'dark') {\n",
        "        url.searchParams.set('__theme', 'dark');\n",
        "        window.location.href = url.href;\n",
        "    }\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "with gr.Blocks(js=js_func, theme=gr.themes.Ocean()) as demo:\n",
        "    gr.Markdown(\"# <center> AI Interviewer </center>\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():  # Left side\n",
        "            job_link = gr.Textbox(label=\"Job Link\")\n",
        "\n",
        "        with gr.Column():  # Right side - buttons stacked vertically\n",
        "            start_btn = gr.Button(\"Start Interview\", variant=\"primary\")\n",
        "            next_btn = gr.Button(\"Next Question\")\n",
        "\n",
        "\n",
        "    #start_btn = gr.Button(\"Start Interview\")\n",
        "    output_audio = gr.Audio(label=\"Bot Response\", autoplay=True)\n",
        "    bot_response_text = gr.Textbox(label=\"Bot Response Text\")\n",
        "\n",
        "    start_btn.click(fn=start_interview, inputs=[job_link], outputs=[output_audio, bot_response_text])\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():  # Left Side - Speech and Transcription\n",
        "            audio_input = gr.Audio(sources=[\"microphone\"], label=\"🎤 Speak Here!\", type=\"numpy\")\n",
        "            transcription_output = gr.Textbox(label=\"Your Response\")  # Removed incorrect 'inputs' argument\n",
        "            next_btn = gr.Button(\"Next Question\")\n",
        "            next_btn.click(fn=ask_next_question, inputs=[], outputs=[output_audio, bot_response_text])\n",
        "\n",
        "        with gr.Column():  # Right Side - Evaluation\n",
        "            submit_button_eval = gr.Button(\"Evaluate\", variant=\"primary\")\n",
        "            evaluation_output = gr.Textbox(label=\"Evaluation\")\n",
        "\n",
        "    # Auto transcription when speech is recorded\n",
        "    audio_input.change(\n",
        "        process_audio,\n",
        "        inputs=[audio_input],\n",
        "        outputs=[transcription_output]\n",
        "    )\n",
        "\n",
        "    # Evaluation logic\n",
        "    submit_button_eval.click(\n",
        "        lambda: \"\\n\".join([str(item['response']) for item in evaluation_responses_list]),\n",
        "        inputs=[],\n",
        "        outputs=evaluation_output\n",
        "    )\n",
        "\n",
        "    gr.Markdown(\"\"\"\n",
        "    ## How to use this app:\n",
        "    1. Click **\"Generate Question\"** to receive a behavioral interview question.\n",
        "    2. Click on the **microphone** and **speak your response**.\n",
        "    3. Click **\"Next Question\"** to generate the next question.\n",
        "    4. Click **\"Evaluate\"** to receive feedback on your answer.\n",
        "    \"\"\")\n",
        "\n",
        "# Launch Gradio App\n",
        "server_name = \"0.0.0.0\"  # Change if needed\n",
        "#demo.launch(server_name=server_name)\n"
      ],
      "metadata": {
        "id": "NWxMQZ_Du87T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "js_func = \"\"\"\n",
        "function refresh() {\n",
        "    const url = new URL(window.location);\n",
        "\n",
        "    if (url.searchParams.get('__theme') !== 'dark') {\n",
        "        url.searchParams.set('__theme', 'dark');\n",
        "        window.location.href = url.href;\n",
        "    }\n",
        "}\n",
        "\"\"\"\n",
        "with gr.Blocks(js=js_func, theme=gr.themes.Ocean()) as demo:\n",
        "    gr.Markdown(\"# <center> AI Interviewer </center>\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():  # Left side\n",
        "            job_link = gr.Textbox(label=\"Job Link\")\n",
        "            #company_name = gr.Textbox(label=\"Company Name\")\n",
        "\n",
        "        with gr.Column():  # Right side - buttons stacked vertically\n",
        "            start_btn = gr.Button(\"Start Interview\", variant=\"primary\")\n",
        "            next_btn = gr.Button(\"Next Question\")\n",
        "\n",
        "    output_audio = gr.Audio(label=\"Bot Response\", autoplay=True)\n",
        "    bot_response_text = gr.Textbox(label=\"Bot Response Text\")\n",
        "\n",
        "    start_btn.click(fn=start_interview, inputs=[job_link], outputs=[output_audio, bot_response_text])\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():  # Left Side - Speech and Transcription\n",
        "            audio_input = gr.Audio(sources=[\"microphone\"], label=\"🎤 Speak Here!\", type=\"numpy\")\n",
        "            transcription_output = gr.Textbox(label=\"Your Response\")\n",
        "            next_btn.click(fn=ask_next_question, inputs=[], outputs=[output_audio, bot_response_text])\n",
        "\n",
        "        with gr.Column():  # Right Side - Evaluation\n",
        "            submit_button_eval = gr.Button(\"Evaluate\", variant=\"primary\")\n",
        "            evaluation_output = gr.Textbox(label=\"Evaluation\")\n",
        "\n",
        "    # Auto transcription when speech is recorded\n",
        "    audio_input.change(\n",
        "        fn=process_audio,\n",
        "        inputs=[audio_input],\n",
        "        outputs=[transcription_output]\n",
        "    )\n",
        "\n",
        "    # Evaluation logic\n",
        "    submit_button_eval.click(\n",
        "        fn=lambda: \"\\n\".join([str(item['response']) for item in evaluation_responses_list]),\n",
        "        inputs=[],\n",
        "        outputs=evaluation_output\n",
        "    )\n",
        "\n",
        "    gr.Markdown(\"\"\"\n",
        "    ## How to use this app:\n",
        "    1. Click **\"Start Interview\"** to begin the interview.\n",
        "    2. Click on the **microphone** and **speak your response**.\n",
        "    3. Click **\"Next Question\"** to generate the next question.\n",
        "    4. Click **\"Evaluate\"** to receive feedback on your answer.\n",
        "    \"\"\")\n",
        "\n",
        "# Launch Gradio App\n",
        "demo.launch(server_name=\"0.0.0.0\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "id": "pZIBdX_5ItE-",
        "outputId": "c258f88f-401f-45f8-f988-76fbf54b600b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://ccb9b96693378f75ea.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://ccb9b96693378f75ea.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    }
  ]
}